{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC5KwRyl6Flp"
      },
      "source": [
        "# Task description\n",
        "- Classify the speakers of given features.\n",
        "\n",
        "- Other links\n",
        "  - Kaggle: [link](https://www.kaggle.com/t/859c9ca9ede14fdea841be627c412322)\n",
        "  - Slide: [link](https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/hw/HW04/HW04.pdf)\n",
        "  - Data: [link](https://drive.google.com/file/d/1T0RPnu-Sg5eIPwQPfYysipfcz81MnsYe/view?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPDoreyypeJE"
      },
      "source": [
        "# Download dataset\n",
        "- **If all download links fail**\n",
        "- **Please follow [here](https://drive.google.com/drive/folders/13T0Pa_WGgQxNkqZk781qhc5T9-zfh19e?usp=sharing)**\n",
        "- **Data is [here](https://drive.google.com/file/d/1T0RPnu-Sg5eIPwQPfYysipfcz81MnsYe/view?usp=sharing)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QvpaILXnJIcw",
        "outputId": "b677b729-66ef-44aa-98d6-bee577654768"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n    For Onedrive, we split dataset into five files. \\n    Please download all of them.\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "    For Google drive, You can download data form any link below.\n",
        "    If a link fails, please use another one.\n",
        "\"\"\"\n",
        "\"\"\" Download link 1 of Google drive \"\"\"\n",
        "# !gdown --id '1T0RPnu-Sg5eIPwQPfYysipfcz81MnsYe' --output Dataset.zip\n",
        "\"\"\" Download link 2 of Google drive \"\"\"\n",
        "# !gdown --id '1CtHZhJ-mTpNsO-MqvAPIi4Yrt3oSBXYV' --output Dataset.zip\n",
        "\"\"\" Download link 3 of Google drive \"\"\"\n",
        "# !gdown --id '14hmoMgB1fe6v50biIceKyndyeYABGrRq' --output Dataset.zip\n",
        "\"\"\" Download link 4 of Google drive \"\"\"\n",
        "# !gdown --id '1e9x-Pjl3n7-9tK9LS_WjiMo2lru4UBH9' --output Dataset.zip\n",
        "\"\"\" Download link 5 of Google drive \"\"\"\n",
        "# !gdown --id '10TC0g46bcAz_jkiMl65zNmwttT4RiRgY' --output Dataset.zip\n",
        "\"\"\" Download link 6 of Google drive \"\"\"\n",
        "# !gdown --id '1MUGBvG_JjqO0C2JYHuyV3B0lvaf1kWIm' --output Dataset.zip\n",
        "\"\"\" Download link 7 of Google drive \"\"\"\n",
        "#!gdown --id '18M91P5DHwILNyOlssZ57AiPOR0OwutOM' --output Dataset.zip\n",
        "\"\"\" For all download links fail, Please paste link into 'Paste link here' \"\"\"\n",
        "#!gdown --id '1QmUnkxG1z6RPUOnTuyQL-WXOOCU9Zpm6' --output Dataset.zip\n",
        "\"\"\" For Google drive, you can unzip the data by the command below. \"\"\"\n",
        "#!unzip Dataset.zip\n",
        "\n",
        "\"\"\"\n",
        "    For Dropbox, we split dataset into five files. \n",
        "    Please download all of them.\n",
        "\"\"\"\n",
        "# If Dropbox is not work. Please use google drive.\n",
        "# !wget https://www.dropbox.com/s/vw324newiku0sz0/Dataset.tar.gz.aa?dl=0\n",
        "# !wget https://www.dropbox.com/s/z840g69e7lnkayo/Dataset.tar.gz.ab?dl=0\n",
        "#!wget https://www.dropbox.com/s/hl081e1ggonio81/Dataset.tar.gz.ac?dl=0\n",
        "# !wget https://www.dropbox.com/s/fh3zd8ow668c4th/Dataset.tar.gz.ad?dl=0\n",
        "# !wget https://www.dropbox.com/s/ydzygoy2pv6gw9d/Dataset.tar.gz.ae?dl=0\n",
        "#!cat Dataset.tar.gz.* | tar zxvf -\n",
        "\n",
        "\"\"\"\n",
        "    For Onedrive, we split dataset into five files. \n",
        "    Please download all of them.\n",
        "\"\"\"\n",
        "# !wget --no-check-certificate \"https://onedrive.live.com/download?cid=10C95EE5FD151BFB&resid=10C95EE5FD151BFB%21106&authkey=ACB6opQR3CG9kmc\" -O Dataset.tar.gz.aa\n",
        "# !wget --no-check-certificate \"https://onedrive.live.com/download?cid=93DDDDD552E145DB&resid=93DDDDD552E145DB%21106&authkey=AP6EepjxSdvyV6Y\" -O Dataset.tar.gz.ab\n",
        "# !wget --no-check-certificate \"https://onedrive.live.com/download?cid=644545816461BCCC&resid=644545816461BCCC%21106&authkey=ALiefB0kI7Epb0Q\" -O Dataset.tar.gz.ac\n",
        "# !wget --no-check-certificate \"https://onedrive.live.com/download?cid=77CEBB3C3C512821&resid=77CEBB3C3C512821%21106&authkey=AAXCx4TTDYC0yjM\" -O Dataset.tar.gz.ad\n",
        "# !wget --no-check-certificate \"https://onedrive.live.com/download?cid=383D0E0146A11B02&resid=383D0E0146A11B02%21106&authkey=ALwVc4StVbig6QI\" -O Dataset.tar.gz.ae\n",
        "# !cat Dataset.tar.gz.* | tar zxvf -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VVoZM_zpQ57",
        "outputId": "41545f00-a66e-4d3a-d825-60d65be3e902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Apr 13 09:52:48 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! /opt/bin/nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lgviMCf37zG",
        "outputId": "d39483cb-eada-4436-9939-702ad6b5c27c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E743THudC-pa",
        "outputId": "a1e5d0ae-c2d2-4d53-82ff-4716aefd8af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mTruncated。\u001b[0m\n",
            "  inflating: Dataset/uttr-13307b1f79fa4c34ae0ac7dd01e550d0.pt  \n",
            "  inflating: Dataset/uttr-addf4e847665455da803a433a0a872f4.pt  \n",
            "  inflating: Dataset/uttr-2f0b654391a44cb3b4335bef62ad7a5a.pt  \n",
            "  inflating: Dataset/uttr-1f05e4d6775144378000b9ffd7ff907f.pt  \n",
            "  inflating: Dataset/uttr-fbae633b89044403a6c056987df8c720.pt  \n",
            "  inflating: Dataset/uttr-6d67740c09c44ccb95541e1fd389d205.pt  \n",
            "  inflating: Dataset/uttr-c9bae6645d62413ea745b8e0580af07c.pt  \n",
            "  inflating: Dataset/uttr-f636fd38b3c2409ab9e760773e9052f4.pt  \n",
            "  inflating: Dataset/uttr-1ef19a9560d44a86a2edbf5c7f21b986.pt  \n",
            "  inflating: Dataset/uttr-f6daf62637d6499a95637c1442dcd19b.pt  \n",
            "  inflating: Dataset/uttr-78b14798360a461f97bfa4fc553d0194.pt  \n",
            "  inflating: Dataset/uttr-8cea670e3aa644b7b0621eb17ba7e0b8.pt  \n",
            "  inflating: Dataset/uttr-5c408eac94694fd2b126cd0cd29617d5.pt  \n",
            "  inflating: Dataset/uttr-b8762ec836aa4ca49c241fc2fbde892f.pt  \n",
            "  inflating: Dataset/uttr-561a27f88e3542c992ecafe22f0238ca.pt  \n",
            "  inflating: Dataset/uttr-6f40d3ab23ef483188a906686f043e8d.pt  \n",
            "  inflating: Dataset/uttr-200b2837554f471cae52cd947fc50d03.pt  \n",
            "  inflating: Dataset/uttr-3d3cc7d335b243668b584ab63671ff32.pt  \n",
            "  inflating: Dataset/uttr-fe692556effa49a4b9c079ee12241982.pt  \n",
            "  inflating: Dataset/uttr-30481135da37494385f35aa8ef4cd570.pt  \n",
            "  inflating: Dataset/uttr-fbe6d70bdd5843819145c84803848406.pt  \n",
            "  inflating: Dataset/uttr-276a3ec567644a51922eba6a809f5b43.pt  \n",
            "  inflating: Dataset/uttr-9b94a8a8fd4248929455c10995a33d2c.pt  \n",
            "  inflating: Dataset/uttr-5077b829b9d14e718442933623d58e63.pt  \n",
            "  inflating: Dataset/uttr-753c95ea5b9e49bbaa9a412e31ed6282.pt  \n",
            "  inflating: Dataset/uttr-591953d93cb74e25acf18fe15a1ea394.pt  \n",
            "  inflating: Dataset/uttr-a355f72dd889475aa35096b24e482c61.pt  \n",
            "  inflating: Dataset/uttr-287a3d5627764f879d45760bf4640fcc.pt  \n",
            "  inflating: Dataset/uttr-50d9dec9ee904047a50b4e6abb1aadb4.pt  \n",
            "  inflating: Dataset/uttr-6f70b74a9e8243ebba2b3aa070d49533.pt  \n",
            "  inflating: Dataset/uttr-afd795cdb8a240e4b478e9f590e87da5.pt  \n",
            "  inflating: Dataset/uttr-9806c85d4e15485a92981c33e6f88536.pt  \n",
            "  inflating: Dataset/uttr-e5958f4565d844d790eba0d0be877b27.pt  \n",
            "  inflating: Dataset/uttr-61f667b1cea24d7aaa354700fbb9cf68.pt  \n",
            "  inflating: Dataset/uttr-669f10be739f44e3ac7b951d78a51846.pt  \n",
            "  inflating: Dataset/uttr-73c578ee782a4125962eb7ea61f9a5d4.pt  \n",
            "  inflating: Dataset/uttr-318cac48efcf4ef68e0b2e08179d74a4.pt  \n",
            "  inflating: Dataset/uttr-cd8af3a8f50545868809bef3f0f823ce.pt  \n",
            "  inflating: Dataset/uttr-9578e5c918a44ee3a7c67833d330339a.pt  \n",
            "  inflating: Dataset/uttr-6ad3f842f26449328f5d89e1222e8a9f.pt  \n",
            "  inflating: Dataset/uttr-67965120ab5c44bf967495bff754f8fa.pt  \n",
            "  inflating: Dataset/uttr-de3ee6f048c143deb29be0e67c306cf2.pt  \n",
            "  inflating: Dataset/uttr-28366f80a2514e7aa38e6855a1531767.pt  \n",
            "  inflating: Dataset/uttr-94e905421f02476b90faec8925e17df3.pt  \n",
            "  inflating: Dataset/uttr-85157227baa94d6ba4b0a00308b75052.pt  \n",
            "  inflating: Dataset/uttr-5215b5857e7440a1bf611e13063c8188.pt  \n",
            "  inflating: Dataset/uttr-f3aa7c93bcff4052b1397c6cae50a041.pt  \n",
            "  inflating: Dataset/uttr-9bc0cef2ef5e416d8b1da67a7b870caa.pt  \n",
            "  inflating: Dataset/uttr-560bc60f04a44258a7713f582bd01398.pt  \n",
            "  inflating: Dataset/uttr-bd431a1644594707af34e37b8d3688d4.pt  \n",
            "  inflating: Dataset/uttr-0b3d54109ddb4b0fb387ec8e6b0c2cad.pt  \n",
            "  inflating: Dataset/uttr-7b3cfe54aca44178aa508251811a4971.pt  \n",
            "  inflating: Dataset/uttr-dcfdbb46225045bbac345868bbd382d2.pt  \n",
            "  inflating: Dataset/uttr-f15a1bad353e4d24b923b8cb8418f342.pt  \n",
            "  inflating: Dataset/uttr-8b72b5a1720f40b7a85d84dd4f4484f3.pt  \n",
            "  inflating: Dataset/uttr-2de12fe4a5cb43b895e0bd15301e9eae.pt  \n",
            "  inflating: Dataset/uttr-b1a59f9b4a10488c8e3f74481e8404c0.pt  \n",
            "  inflating: Dataset/uttr-241f57a11f5746a69f7899d9dfa9952b.pt  \n",
            "  inflating: Dataset/uttr-3bbfac407a2c47c9a349eab77712ff07.pt  \n",
            "  inflating: Dataset/uttr-e87d124dbf524566b4d5d4db36e14ca5.pt  \n",
            "  inflating: Dataset/uttr-a2b3e866589d4377ae36b3f9e51e56a0.pt  \n",
            "  inflating: Dataset/uttr-9256358cdb694effb61747a6c56e6b5e.pt  \n",
            "  inflating: Dataset/uttr-5702caa1737f4b3493b051a59bb5d13e.pt  \n",
            "  inflating: Dataset/uttr-15e745bb23ae4303b6bcc8be152ef73f.pt  \n",
            "  inflating: Dataset/uttr-bceeb73fabde4964ae90f44c9516dd46.pt  \n",
            "  inflating: Dataset/uttr-9440103f8a78405a9ae0488b5f2dfd8d.pt  \n",
            "  inflating: Dataset/uttr-c1747c96ee144804a6f6d807652864a1.pt  \n",
            "  inflating: Dataset/uttr-b3325f1ca82e4b3a834520e63c6a7e9b.pt  \n",
            "  inflating: Dataset/uttr-4cbd7c622e8b4a08804b8b36cb5fbc6f.pt  \n",
            "  inflating: Dataset/uttr-f502481f10d94d8f89f612d584c4222a.pt  \n",
            "  inflating: Dataset/uttr-3e56db49b7f9413ebd0d452660f76e48.pt  \n",
            "  inflating: Dataset/uttr-ecdc1f34f2de4364836dc8fe4a757129.pt  \n",
            "  inflating: Dataset/uttr-88717355216645f9b58b12cadaec549f.pt  \n",
            "  inflating: Dataset/uttr-018ded825efd4e8689251c82ed106e1e.pt  \n",
            "  inflating: Dataset/uttr-e9c23eb68d9748418db42c3ea6d72d72.pt  \n",
            "  inflating: Dataset/uttr-3cc8022a07364712a1f2b257a77d6e17.pt  \n",
            "  inflating: Dataset/uttr-f5f54efb4eab4d8ebbe63522c49dc005.pt  \n",
            "  inflating: Dataset/uttr-9b2558a4e8dd44e094995d8a1b6ffd87.pt  \n",
            "  inflating: Dataset/uttr-fccbba73d71748ea8b3f19a7db5fc614.pt  \n",
            "  inflating: Dataset/uttr-98f26f6e90c34c5796a8b1b4f45ca84e.pt  \n",
            "  inflating: Dataset/uttr-2169a44082b348b6970a988707672446.pt  \n",
            "  inflating: Dataset/uttr-6a471bfc0bd448898a4d681a621db79a.pt  \n",
            "  inflating: Dataset/uttr-c10e5e1eeb984c92b691106ff57e2cfc.pt  \n",
            "  inflating: Dataset/uttr-e15cdab2f7694023a06158dc2e45f552.pt  \n",
            "  inflating: Dataset/uttr-3d3f712b1bee468696cd07d18939c439.pt  \n",
            "  inflating: Dataset/uttr-298d667593e24917a33ebea294fab4a3.pt  \n",
            "  inflating: Dataset/uttr-4f50a8af0ec144f4aac4f65e0cd32ff7.pt  \n",
            "  inflating: Dataset/uttr-c0d4abf705b741c38b3da3dd7c49d04a.pt  \n",
            "  inflating: Dataset/uttr-72b5ea5703ce4df8a7e6a3f6baf69f72.pt  \n",
            "  inflating: Dataset/uttr-a75bee5be1d84b84b7cc33b6ca0f8064.pt  \n",
            "  inflating: Dataset/uttr-aa2f8ffeb23d4ffeaf787d475f0cc85f.pt  \n",
            "  inflating: Dataset/uttr-5cafb6b9e351483887a73ecbc012058f.pt  \n",
            "  inflating: Dataset/uttr-a00c30d03b984c4798482d9bb4ae8bf1.pt  \n",
            "  inflating: Dataset/uttr-66ad834db6db40768e345d8125284226.pt  \n",
            "  inflating: Dataset/uttr-7247f79a6fc34935bc9bb94f298eb973.pt  \n",
            "  inflating: Dataset/uttr-97867b171daf4a589b26a14b334e472b.pt  \n",
            "  inflating: Dataset/uttr-a4e24400926441349ff3b39962b3f2f8.pt  \n",
            "  inflating: Dataset/uttr-c03e31b8eb37452bb2eb42aecdc3abe9.pt  \n",
            "  inflating: Dataset/uttr-49835dbacb12465697ff3e45b4174b6f.pt  \n",
            "  inflating: Dataset/uttr-c13ff33033ba429b85832253415c6c6e.pt  \n",
            "  inflating: Dataset/uttr-af72e2c2163a4c54ba9974b6873ee7c4.pt  \n",
            "  inflating: Dataset/uttr-eb46e1509cdf44b2b0eafb2b4962e5b4.pt  \n",
            "  inflating: Dataset/uttr-872804c139704953829d87a88397b0db.pt  \n",
            "  inflating: Dataset/uttr-cacba4d520ae415d921d857e0e11020f.pt  \n",
            "  inflating: Dataset/uttr-4faa93f4ddf44117bcee00f260c6ab8e.pt  \n",
            "  inflating: Dataset/uttr-df7bdd44b8c747ff9c54364e803c6cb7.pt  \n",
            "  inflating: Dataset/uttr-047929d0ffe54d7cb855766d7c62b08c.pt  \n",
            "  inflating: Dataset/uttr-e2074c4e1b4d425fb4c16a82f774d075.pt  \n",
            "  inflating: Dataset/uttr-e2ea759d39b0443ebec4a75b263bf0ee.pt  \n",
            "  inflating: Dataset/uttr-d53c2348c3794cd5bbd70a93ca50bc7b.pt  \n",
            "  inflating: Dataset/uttr-897ce92bf22e402b8bcb5a38ca8d4c9f.pt  \n",
            "  inflating: Dataset/uttr-a719b7d8e3934f2494bef8d0762682e8.pt  \n",
            "  inflating: Dataset/uttr-e990d4b0617546e8a5c813f96f820392.pt  \n",
            "  inflating: Dataset/uttr-40c6beae3d614e07a494e9e52dc6c91b.pt  \n",
            "  inflating: Dataset/uttr-c73e6f16f8954439baffed8ba45e1a69.pt  \n",
            "  inflating: Dataset/uttr-46669a161ff648ffbfe3c073e6140eef.pt  \n",
            "  inflating: Dataset/uttr-eccedb5bc2ac4c16bc8ae79f28e31d59.pt  \n",
            "  inflating: Dataset/uttr-29fa72b231b540db930d9761c8a0b8d0.pt  \n",
            "  inflating: Dataset/uttr-620ade8470d44aec9d179ae11c09ae81.pt  \n",
            "  inflating: Dataset/uttr-c12ac87bdd6346e4a14a87301659df2b.pt  \n",
            "  inflating: Dataset/uttr-f6b73a43c1b84b8b916feb3e2fd8e695.pt  \n",
            "  inflating: Dataset/uttr-ad3710790c06407c99c52e3657b5bd1e.pt  \n",
            "  inflating: Dataset/uttr-cb845c5546694b03b3afd7f2abf6606d.pt  \n",
            "  inflating: Dataset/uttr-18de733a02544992b70b5cb397f080fc.pt  \n",
            "  inflating: Dataset/uttr-5a99d7cadfb3422888c8dccde9a21cb2.pt  \n",
            "  inflating: Dataset/uttr-82fbd7c61090496e8a8ac88b5605cf6b.pt  \n",
            "  inflating: Dataset/uttr-9760366058594dd0aed7a543912babf8.pt  \n",
            "  inflating: Dataset/uttr-98ca2bd8dc624131b8166b5b8eeded5b.pt  \n",
            "  inflating: Dataset/uttr-024ff5347b3341578bfcb859d886a60f.pt  \n",
            "  inflating: Dataset/uttr-1cc5f674602e445292bfbb466e94fae6.pt  \n",
            "  inflating: Dataset/uttr-946d4b39f1b244bc8d42dcd5b7025e90.pt  \n",
            "  inflating: Dataset/uttr-ada9d8da008a4ea68db1dcad7ca96bdc.pt  \n",
            "  inflating: Dataset/uttr-0b4dcaaa55174f8bbcd74483ad5ba167.pt  \n",
            "  inflating: Dataset/uttr-635470afec6044038af096f05f8dca1c.pt  \n",
            "  inflating: Dataset/uttr-dca55e3798ba4eba93e3ae7325aaad44.pt  \n",
            "  inflating: Dataset/uttr-66a0736119464da39473eed9a5412623.pt  \n",
            "  inflating: Dataset/uttr-2cabb85cc2d04feb93c800e6555d87fa.pt  \n",
            "  inflating: Dataset/uttr-afeff866ea2c455fae07e4117d768dde.pt  \n",
            "  inflating: Dataset/uttr-d548d8c8f0e34214a5b5942ab8d4dbfb.pt  \n",
            "  inflating: Dataset/uttr-55c25c15ba1644c09d89dc776fe9458b.pt  \n",
            "  inflating: Dataset/uttr-ffc807c94b684d95ab25cf8ecbcb3d71.pt  \n",
            "  inflating: Dataset/uttr-2833127806ff4d65a9c133bcb95483af.pt  \n",
            "  inflating: Dataset/uttr-4826f6be4898436b9ba00cfe0c3699ea.pt  \n",
            "  inflating: Dataset/uttr-1c84921682bd4894aa501062ce4a945b.pt  \n",
            "  inflating: Dataset/uttr-c866d3fed0a440b79be6ab07166987de.pt  \n",
            "  inflating: Dataset/uttr-9543b49b98a6461b90c3074751cf0ce8.pt  \n",
            "  inflating: Dataset/uttr-c21b0e73e15a4fab98c666689b5286b3.pt  \n",
            "  inflating: Dataset/uttr-01572b1a751b4cf48b0bcf42605f72f7.pt  \n",
            "  inflating: Dataset/uttr-af501539df654696a15273fc2b36b093.pt  \n",
            "  inflating: Dataset/uttr-ad246a2a27494bfaa241e95b994b17bf.pt  \n",
            "  inflating: Dataset/uttr-673e58da485249f2a08b978f32fdc63f.pt  \n",
            "  inflating: Dataset/uttr-563607e2419b492da0c8527795cc0fc4.pt  \n",
            "  inflating: Dataset/uttr-7ee96b2fbbe34097b8cce224a9b4ec37.pt  \n",
            "  inflating: Dataset/uttr-c14b013fb8734dc1bd8aa274b22f5378.pt  \n",
            "  inflating: Dataset/uttr-b0c40019c66946ccac990acfd9c74a84.pt  \n",
            "  inflating: Dataset/uttr-3bc20669b5fc4333ac36188ac7ee4732.pt  \n",
            "  inflating: Dataset/uttr-f5d134e95ad242869ca2d54303af2006.pt  \n",
            "  inflating: Dataset/uttr-1f5bb07e959946bfa31e16897aedd3f1.pt  \n",
            "  inflating: Dataset/uttr-15bb79aaf7ee4c44ac6b20bdf20c258d.pt  \n",
            "  inflating: Dataset/uttr-5e9c13f1fbef4ca288382b5a48a8c693.pt  \n",
            "  inflating: Dataset/uttr-fedbe200620a433e8aff0f154a41c62e.pt  \n",
            "  inflating: Dataset/uttr-b1142131c54d42e88a4c4e6ae51c94e4.pt  \n",
            "  inflating: Dataset/uttr-8e94744ccb2b4b65810037aa34dd651a.pt  \n",
            "  inflating: Dataset/uttr-fc21bb297355478c857b4923480397c6.pt  \n",
            "  inflating: Dataset/uttr-706a27f029064264a98d99bedc85198f.pt  \n",
            "  inflating: Dataset/uttr-a6c5e95faf5f49fcaf234e2b0aa4a75e.pt  \n",
            "  inflating: Dataset/uttr-4f1ef98970244f988cafc9ede9c98788.pt  \n",
            "  inflating: Dataset/uttr-10e2ff879f834337a0b9106c8bc5241d.pt  \n",
            "  inflating: Dataset/uttr-16ac5c696af44d5a9ed593b6b3ae9dab.pt  \n",
            "  inflating: Dataset/uttr-7239dd98a0bc44dcab109fb0aed61eb6.pt  \n",
            "  inflating: Dataset/uttr-2dfff3e9cee24eebab9231eca002104c.pt  \n",
            "  inflating: Dataset/uttr-400fdaa03f4b4f9cb53c5201829ecb5d.pt  \n",
            "  inflating: Dataset/uttr-32b520c1c1a5478abab799824aef868d.pt  \n",
            "  inflating: Dataset/uttr-8d8e3aac46ec42549821f626e9db3884.pt  \n",
            "  inflating: Dataset/uttr-4129f57e68be4bfa91a1302aed71d261.pt  \n",
            "  inflating: Dataset/uttr-4da4a3b43567454ab813e4cfa11cab35.pt  \n",
            "  inflating: Dataset/uttr-5c3e1794f1314284bf622f59f7ec7f11.pt  \n",
            "  inflating: Dataset/uttr-bbb12f9997e4486680367ab6a0c2fc12.pt  \n",
            "  inflating: Dataset/uttr-128ff189047a4709aa076590e551f529.pt  \n",
            "  inflating: Dataset/uttr-0cd509d8a495477581778273b612fbab.pt  \n",
            "  inflating: Dataset/uttr-40aa208231ce44bbb5bda051691852d1.pt  \n",
            "  inflating: Dataset/uttr-c2777bd1589647c9844df00023b13c88.pt  \n",
            "  inflating: Dataset/uttr-2202576895274cc98ceeca16b13ea8a9.pt  \n",
            "  inflating: Dataset/uttr-bf6ed6e8ec4f4754a193967cad75e3b6.pt  \n",
            "  inflating: Dataset/uttr-c78976fdda444620af528abbd93b2e2f.pt  \n",
            "  inflating: Dataset/uttr-a4f035e69e824f9ba45abf64e02c12b8.pt  \n",
            "  inflating: Dataset/uttr-494a78e4007c4fea8ed3605588da6294.pt  \n",
            "  inflating: Dataset/uttr-332d1081c182431288cb86d4f8475482.pt  \n",
            "  inflating: Dataset/uttr-df424e81631b46acb31137bd49cfa82d.pt  \n",
            "  inflating: Dataset/uttr-e4e64b9cbafa48fe8b472a21d9f46b47.pt  \n",
            "  inflating: Dataset/uttr-53303bff1f32474da56d7cf77312390b.pt  \n",
            "  inflating: Dataset/uttr-5572fa79e91448c49f420d13865616f3.pt  \n",
            "  inflating: Dataset/uttr-2382823b1f7449839e60ae874559db6d.pt  \n",
            "  inflating: Dataset/uttr-d99dc83d92254fb7812e47bbe6aea64f.pt  \n",
            "  inflating: Dataset/uttr-dcfc0a66d1f743d9a3621e226bb7e4c1.pt  \n",
            "  inflating: Dataset/uttr-2ccba4faa524410ca15d92a397fc7fee.pt  \n",
            "  inflating: Dataset/uttr-089b910e2e234807ac4cbe65c36bf470.pt  \n",
            "  inflating: Dataset/uttr-e9c3302da7014b0280bd19e88796e2b1.pt  \n",
            "  inflating: Dataset/uttr-4b4262dc6ff448eb9fe4df455c3e8509.pt  \n",
            "  inflating: Dataset/uttr-3f6c396f50dc4d53b05d19d98ea5dc47.pt  \n",
            "  inflating: Dataset/uttr-2de1ee5fce464f6fafcdad34fc261ecf.pt  \n",
            "  inflating: Dataset/uttr-f6b8b6b203be49dd94428962613bc45a.pt  \n",
            "  inflating: Dataset/uttr-b918d89d934a45e0a48a0c567beb581a.pt  \n",
            "  inflating: Dataset/uttr-86110df2c1fb4f8fbd0d04b7e517c166.pt  \n",
            "  inflating: Dataset/uttr-6f6837d8e2454940a343461574dd3485.pt  \n",
            "  inflating: Dataset/uttr-30a4f9d824f74343aa78f82dc92a278d.pt  \n",
            "  inflating: Dataset/uttr-5353601e123647108b6357dbe5af0862.pt  \n",
            "  inflating: Dataset/uttr-4c91eae7e5b446bcb5a6e679106e8cde.pt  \n",
            "  inflating: Dataset/uttr-40b6e971ab7e4b2da5de9754632580c7.pt  \n",
            "  inflating: Dataset/uttr-24dd1a7388a342288034fb647bcf89df.pt  \n",
            "  inflating: Dataset/uttr-7771632a692f44809dc45c918c91c792.pt  \n",
            "  inflating: Dataset/uttr-c4eeb491f1234561af0ba9954a853d88.pt  \n",
            "  inflating: Dataset/uttr-c052c93735774f3c8a8de828387afd23.pt  \n",
            "  inflating: Dataset/uttr-49afb86c51314c4fa264d9b21da3fd71.pt  \n",
            "  inflating: Dataset/uttr-6d4e3ea901a44460bbdfd0a333e0d0b7.pt  \n",
            "  inflating: Dataset/uttr-81b171d74be647be8b6c3cc592f977ee.pt  \n",
            "  inflating: Dataset/uttr-0c5d0f803622478ab779c5525290c4c1.pt  \n",
            "  inflating: Dataset/uttr-8521ede8dcc4420ca4c822593a45e06f.pt  \n",
            "  inflating: Dataset/uttr-e207535472cb4129a6d6a9c4f7807d4a.pt  \n",
            "  inflating: Dataset/uttr-6faeb4da0e3e4e37b4ac2ea08c03c8a9.pt  \n",
            "  inflating: Dataset/uttr-6b1de40629d4447d8990e9675a9d461d.pt  \n",
            "  inflating: Dataset/uttr-363c929853004b37ba03d441efbab912.pt  \n",
            "  inflating: Dataset/uttr-0971b25199964237b39aec792d396607.pt  \n",
            "  inflating: Dataset/uttr-0b5c9a69890046a6838b3505666d588c.pt  \n",
            "  inflating: Dataset/uttr-c295b13641f043e4aa92e4b377f5258d.pt  \n",
            "  inflating: Dataset/uttr-82e4b19e6ab149d5a7f62ce6f24867af.pt  \n",
            "  inflating: Dataset/uttr-cb7d7ae9cf3342e9a5f88d8e38c5042c.pt  \n",
            "  inflating: Dataset/uttr-df6ec88c3d324a4bb4315e01f439f962.pt  \n",
            "  inflating: Dataset/uttr-b12e86996f724e4c8a4b5773093d9b18.pt  \n",
            "  inflating: Dataset/uttr-eb3df0ac7f7345ada0e48ebcc33e5058.pt  \n",
            "  inflating: Dataset/uttr-3477c3c2e8f149bfa908d0f782819414.pt  \n",

            "Dataset  drive\tsample_data\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!unzip \"/content/drive/MyDrive/Dataset.zip\"\n",
        "!ls "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1gYr_aoNDue"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz_NpuAipk3h"
      },
      "source": [
        "## Dataset\n",
        "- Original dataset is [Voxceleb1](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/).\n",
        "- The [license](https://creativecommons.org/licenses/by/4.0/) and [complete version](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/files/license.txt) of Voxceleb1.\n",
        "- We randomly select 600 speakers from Voxceleb1.\n",
        "- Then preprocess the raw waveforms into mel-spectrograms.\n",
        "\n",
        "- Args:\n",
        "  - data_dir: The path to the data directory.\n",
        "  - metadata_path: The path to the metadata.\n",
        "  - segment_len: The length of audio segment for training. \n",
        "- The architecture of data directory \\\\\n",
        "  - data directory \\\\\n",
        "  |---- metadata.json \\\\\n",
        "  |---- testdata.json \\\\\n",
        "  |---- mapping.json \\\\\n",
        "  |---- uttr-{random string}.pt \\\\\n",
        "\n",
        "- The information in metadata\n",
        "  - \"n_mels\": The dimention of mel-spectrogram.\n",
        "  - \"speakers\": A dictionary. \n",
        "    - Key: speaker ids.\n",
        "    - value: \"feature_path\" and \"mel_len\"\n",
        "\n",
        "\n",
        "For efficiency, we segment the mel-spectrograms into segments in the traing step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd7hoGhYtbXQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        " \n",
        " \n",
        "class myDataset(Dataset):\n",
        "  def __init__(self, data_dir, segment_len=128):\n",
        "    self.data_dir = data_dir\n",
        "    self.segment_len = segment_len\n",
        " \n",
        "    # Load the mapping from speaker neme to their corresponding id. \n",
        "    mapping_path = Path(data_dir) / \"mapping.json\"\n",
        "    mapping = json.load(mapping_path.open())\n",
        "    self.speaker2id = mapping[\"speaker2id\"]\n",
        " \n",
        "    # Load metadata of training data.\n",
        "    metadata_path = Path(data_dir) / \"metadata.json\"\n",
        "    metadata = json.load(open(metadata_path))[\"speakers\"]\n",
        " \n",
        "    # Get the total number of speaker.\n",
        "    self.speaker_num = len(metadata.keys())\n",
        "    self.data = []\n",
        "    for speaker in metadata.keys():\n",
        "      for utterances in metadata[speaker]:\n",
        "        self.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n",
        " \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        " \n",
        "  def __getitem__(self, index):\n",
        "    feat_path, speaker = self.data[index]\n",
        "    # Load preprocessed mel-spectrogram.\n",
        "    mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
        " \n",
        "    # Segmemt mel-spectrogram into \"segment_len\" frames.\n",
        "    if len(mel) > self.segment_len:\n",
        "      # Randomly get the starting point of the segment.\n",
        "      start = random.randint(0, len(mel) - self.segment_len)\n",
        "      # Get a segment with \"segment_len\" frames.\n",
        "      mel = torch.FloatTensor(mel[start:start+self.segment_len])\n",
        "    else:\n",
        "      mel = torch.FloatTensor(mel)\n",
        "    # Turn the speaker id into long for computing loss later.\n",
        "    speaker = torch.FloatTensor([speaker]).long()\n",
        "    return mel, speaker\n",
        " \n",
        "  def get_speaker_number(self):\n",
        "    return self.speaker_num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqJxjoi_NGnB"
      },
      "source": [
        "## Dataloader\n",
        "- Split dataset into training dataset(90%) and validation dataset(10%).\n",
        "- Create dataloader to iterate the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuT1AuFENI8t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "  # Process features within a batch.\n",
        "  \"\"\"Collate a batch of data.\"\"\"\n",
        "  mel, speaker = zip(*batch)\n",
        "  # Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.\n",
        "  mel = pad_sequence(mel, batch_first=True, padding_value=-20)    # pad log 10^(-20) which is very small value.\n",
        "  # mel: (batch size, length, 40)\n",
        "  return mel, torch.FloatTensor(speaker).long()\n",
        "\n",
        "\n",
        "def get_dataloader(data_dir, batch_size, n_workers):\n",
        "  \"\"\"Generate dataloader\"\"\"\n",
        "  dataset = myDataset(data_dir)\n",
        "  speaker_num = dataset.get_speaker_number()\n",
        "  # Split dataset into training dataset and validation dataset\n",
        "  trainlen = int(0.9 * len(dataset))\n",
        "  lengths = [trainlen, len(dataset) - trainlen]\n",
        "  trainset, validset = random_split(dataset, lengths)\n",
        "\n",
        "  train_loader = DataLoader(\n",
        "    trainset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=n_workers,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_batch,\n",
        "  )\n",
        "  valid_loader = DataLoader(\n",
        "    validset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=n_workers,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_batch,\n",
        "  )\n",
        "\n",
        "  return train_loader, valid_loader, speaker_num\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBDguwVq2ZVj",
        "outputId": "0203ddd3-b8b2-4948-eb06-4a0e7a990398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting conformer\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/91/5ea88e5e9448f8cc3b109604da5f197f0fa6e13a0d557e9b46445aae22c0/conformer-0.2.3-py3-none-any.whl\n",
            "Collecting einops\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from conformer) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->conformer) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->conformer) (3.7.4.3)\n",
            "Installing collected packages: einops, conformer\n",
            "Successfully installed conformer-0.2.3 einops-0.3.0\n"
          ]
        }
      ],
      "source": [
        "pip install conformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiMbJuRQ2grF"
      },
      "outputs": [],
      "source": [
        "from conformer import ConformerBlock\n",
        "#Reference\n",
        "#https://github.com/lucidrains/conformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0x6eXiHpr4R"
      },
      "source": [
        "# Model\n",
        "- TransformerEncoderLayer:\n",
        "  - Base transformer encoder layer in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
        "  - Parameters:\n",
        "    - d_model: the number of expected features of the input (required).\n",
        "\n",
        "    - nhead: the number of heads of the multiheadattention models (required).\n",
        "\n",
        "    - dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
        "\n",
        "    - dropout: the dropout value (default=0.1).\n",
        "\n",
        "    - activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
        "\n",
        "- TransformerEncoder:\n",
        "  - TransformerEncoder is a stack of N transformer encoder layers\n",
        "  - Parameters:\n",
        "    - encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
        "\n",
        "    - num_layers: the number of sub-encoder-layers in the encoder (required).\n",
        "\n",
        "    - norm: the layer normalization component (optional)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHX4eVj4tjtd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, d_model=160, n_spks=600, dropout=0.2):\n",
        "    super().__init__()\n",
        "    # Project the dimension of features from that of input into d_model.\n",
        "    self.prenet = nn.Linear(40, d_model)\n",
        "    #   Change Transformer to Conformer.\n",
        "    #   https://arxiv.org/abs/2005.08100\n",
        "    #self.encoder_layer = nn.TransformerEncoderLayer(\n",
        "    #  d_model=d_model, dim_feedforward=256, nhead=1\n",
        "    #)\n",
        "    #self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
        "\n",
        "    # Project the the dimension of features from d_model into speaker nums.\n",
        "    self.pred_layer = nn.Sequential(\n",
        "\n",
        "      nn.Linear(d_model, n_spks),\n",
        "    )\n",
        "    self.block  = ConformerBlock(\n",
        "      dim = d_model,\n",
        "      dim_head = n_spks,\n",
        "      heads = 1,\n",
        "      ff_mult = 4,\n",
        "      conv_expansion_factor = 2,\n",
        "      conv_kernel_size = 31,\n",
        "      attn_dropout = 0.,\n",
        "      ff_dropout = 0.,\n",
        "      conv_dropout = 0.\n",
        "  )\n",
        "\n",
        "  def forward(self, mels):\n",
        "    \"\"\"\n",
        "    args:\n",
        "      mels: (batch size, length, 40)\n",
        "    return:\n",
        "      out: (batch size, n_spks)\n",
        "    \"\"\"\n",
        "    # out: (batch size, length, d_model)\n",
        "    out = self.prenet(mels)\n",
        "    # out: (length, batch size, d_model)\n",
        "    out = out.permute(1, 0, 2)\n",
        "    # The encoder layer expect features in the shape of (length, batch size, d_model).\n",
        "    out = self.block(out)\n",
        "    # out: (batch size, length, d_model)\n",
        "    out = out.transpose(0, 1)\n",
        "    # mean pooling\n",
        "    stats = out.mean(dim=1)\n",
        "\n",
        "    # out: (batch, n_spks)\n",
        "    out = self.pred_layer(stats)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-__DolPGpvDZ"
      },
      "source": [
        "# Learning rate schedule\n",
        "- For transformer architecture, the design of learning rate schedule is different from that of CNN.\n",
        "- Previous works show that the warmup of learning rate is useful for training models with transformer architectures.\n",
        "- The warmup schedule\n",
        "  - Set learning rate to 0 in the beginning.\n",
        "  - The learning rate increases linearly from 0 to initial learning rate during warmup period."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-0816BntqT9"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(\n",
        "  optimizer: Optimizer,\n",
        "  num_warmup_steps: int,\n",
        "  num_training_steps: int,\n",
        "  num_cycles: float = 0.5,\n",
        "  last_epoch: int = -1,\n",
        "):\n",
        "  \"\"\"\n",
        "  Create a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "  initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "  initial lr set in the optimizer.\n",
        "\n",
        "  Args:\n",
        "    optimizer (:class:`~torch.optim.Optimizer`):\n",
        "      The optimizer for which to schedule the learning rate.\n",
        "    num_warmup_steps (:obj:`int`):\n",
        "      The number of steps for the warmup phase.\n",
        "    num_training_steps (:obj:`int`):\n",
        "      The total number of training steps.\n",
        "    num_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
        "      The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
        "      following a half-cosine).\n",
        "    last_epoch (:obj:`int`, `optional`, defaults to -1):\n",
        "      The index of the last epoch when resuming training.\n",
        "\n",
        "  Return:\n",
        "    :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
        "  \"\"\"\n",
        "\n",
        "  def lr_lambda(current_step):\n",
        "    # Warmup\n",
        "    if current_step < num_warmup_steps:\n",
        "      return float(current_step) / float(max(1, num_warmup_steps))\n",
        "    # decadence\n",
        "    progress = float(current_step - num_warmup_steps) / float(\n",
        "      max(1, num_training_steps - num_warmup_steps)\n",
        "    )\n",
        "    return max(\n",
        "      0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
        "    )\n",
        "\n",
        "  return LambdaLR(optimizer, lr_lambda, last_epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP03FFo9K8DS"
      },
      "source": [
        "# Model Function\n",
        "- Model forward function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fohaLEFJK9-t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def model_fn(batch, model, criterion, device):\n",
        "  \"\"\"Forward a batch through the model.\"\"\"\n",
        "\n",
        "  mels, labels = batch\n",
        "  mels = mels.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "  outs = model(mels)\n",
        "\n",
        "  loss = criterion(outs, labels)\n",
        "\n",
        "  # Get the speaker id with highest probability.\n",
        "  preds = outs.argmax(1)\n",
        "  # Compute accuracy.\n",
        "  accuracy = torch.mean((preds == labels).float())\n",
        "\n",
        "  return loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7cg-YrzLQcf"
      },
      "source": [
        "# Validate\n",
        "- Calculate accuracy of the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD-_p6nWLO2L"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "\n",
        "def valid(dataloader, model, criterion, device): \n",
        "  \"\"\"Validate on validation set.\"\"\"\n",
        "\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  running_accuracy = 0.0\n",
        "  pbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\" uttr\")\n",
        "\n",
        "  for i, batch in enumerate(dataloader):\n",
        "    with torch.no_grad():\n",
        "      loss, accuracy = model_fn(batch, model, criterion, device)\n",
        "      running_loss += loss.item()\n",
        "      running_accuracy += accuracy.item()\n",
        "\n",
        "    pbar.update(dataloader.batch_size)\n",
        "    pbar.set_postfix(\n",
        "      loss=f\"{running_loss / (i+1):.2f}\",\n",
        "      accuracy=f\"{running_accuracy / (i+1):.2f}\",\n",
        "    )\n",
        "\n",
        "  pbar.close()\n",
        "  model.train()\n",
        "\n",
        "  return running_accuracy / len(dataloader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noHXyal5p1W5"
      },
      "source": [
        "# Main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chRQE7oYtw62",
        "outputId": "f11a55cd-6e68-49b6-a6f2-cae24fe71fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Use cuda now!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Finish loading data!\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [02:03<00:00, 16.24 step/s, accuracy=0.34, loss=3.75, step=2000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 546.33 uttr/s, accuracy=0.26, loss=3.72]\n",
            "Train: 100% 2000/2000 [01:41<00:00, 19.71 step/s, accuracy=0.34, loss=2.77, step=4000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 560.78 uttr/s, accuracy=0.42, loss=2.74]\n",
            "Train: 100% 2000/2000 [01:40<00:00, 19.81 step/s, accuracy=0.53, loss=1.58, step=6000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 554.50 uttr/s, accuracy=0.52, loss=2.18]\n",
            "Train: 100% 2000/2000 [01:39<00:00, 20.04 step/s, accuracy=0.75, loss=1.49, step=8000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 558.41 uttr/s, accuracy=0.58, loss=1.88]\n",
            "Train: 100% 2000/2000 [01:38<00:00, 20.28 step/s, accuracy=0.66, loss=1.57, step=1e+4]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 552.66 uttr/s, accuracy=0.63, loss=1.65]\n",
            "Train:   0% 8/2000 [00:00<01:25, 23.22 step/s, accuracy=0.81, loss=1.01, step=1e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 10000, best model saved. (accuracy=0.6251)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:38<00:00, 20.29 step/s, accuracy=0.78, loss=1.05, step=12000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 556.17 uttr/s, accuracy=0.66, loss=1.53]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.62 step/s, accuracy=0.72, loss=1.30, step=14000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 562.97 uttr/s, accuracy=0.68, loss=1.41]\n",
            "Train: 100% 2000/2000 [01:38<00:00, 20.36 step/s, accuracy=0.72, loss=0.90, step=16000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 545.15 uttr/s, accuracy=0.69, loss=1.35]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.69 step/s, accuracy=0.81, loss=0.84, step=18000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 539.90 uttr/s, accuracy=0.71, loss=1.26]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.73 step/s, accuracy=0.78, loss=1.01, step=2e+4]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 549.45 uttr/s, accuracy=0.71, loss=1.25]\n",
            "Train:   0% 7/2000 [00:00<02:36, 12.72 step/s, accuracy=0.84, loss=0.62, step=2e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 20000, best model saved. (accuracy=0.7136)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:34<00:00, 21.07 step/s, accuracy=0.78, loss=0.70, step=22000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 537.15 uttr/s, accuracy=0.73, loss=1.17]\n",
            "Train: 100% 2000/2000 [01:34<00:00, 21.11 step/s, accuracy=0.84, loss=0.81, step=24000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 556.29 uttr/s, accuracy=0.73, loss=1.14]\n",
            "Train: 100% 2000/2000 [01:35<00:00, 21.03 step/s, accuracy=0.91, loss=0.38, step=26000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 559.36 uttr/s, accuracy=0.75, loss=1.08]\n",
            "Train: 100% 2000/2000 [01:33<00:00, 21.29 step/s, accuracy=0.78, loss=0.82, step=28000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 561.94 uttr/s, accuracy=0.75, loss=1.08]\n",
            "Train: 100% 2000/2000 [01:34<00:00, 21.26 step/s, accuracy=0.91, loss=0.60, step=3e+4]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 554.78 uttr/s, accuracy=0.76, loss=1.06]\n",
            "Train:   0% 8/2000 [00:00<01:34, 21.13 step/s, accuracy=0.88, loss=0.53, step=3e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 30000, best model saved. (accuracy=0.7563)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:33<00:00, 21.41 step/s, accuracy=0.78, loss=0.78, step=32000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 556.63 uttr/s, accuracy=0.76, loss=1.02]\n",
            "Train: 100% 2000/2000 [01:33<00:00, 21.48 step/s, accuracy=0.91, loss=0.79, step=34000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 551.70 uttr/s, accuracy=0.77, loss=1.01]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.55 step/s, accuracy=0.91, loss=0.42, step=36000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 551.84 uttr/s, accuracy=0.77, loss=0.98]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.74 step/s, accuracy=0.91, loss=0.38, step=38000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 549.72 uttr/s, accuracy=0.78, loss=0.93]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.62 step/s, accuracy=0.84, loss=0.55, step=4e+4]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 542.81 uttr/s, accuracy=0.78, loss=0.93]\n",
            "Train:   0% 8/2000 [00:00<01:27, 22.72 step/s, accuracy=0.75, loss=0.68, step=4e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 40000, best model saved. (accuracy=0.7833)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:30<00:00, 21.99 step/s, accuracy=0.91, loss=0.27, step=42000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 542.87 uttr/s, accuracy=0.79, loss=0.90]\n",
            "Train: 100% 2000/2000 [01:31<00:00, 21.93 step/s, accuracy=0.88, loss=0.44, step=44000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 540.31 uttr/s, accuracy=0.78, loss=0.95]\n",
            "Train: 100% 2000/2000 [01:29<00:00, 22.24 step/s, accuracy=0.81, loss=0.60, step=46000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 534.58 uttr/s, accuracy=0.78, loss=0.93]\n",
            "Train: 100% 2000/2000 [01:30<00:00, 22.05 step/s, accuracy=0.81, loss=0.85, step=48000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 535.74 uttr/s, accuracy=0.78, loss=0.94]\n",
            "Train: 100% 2000/2000 [01:31<00:00, 21.92 step/s, accuracy=0.81, loss=0.44, step=5e+4]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 512.96 uttr/s, accuracy=0.79, loss=0.93]\n",
            "Train:   0% 8/2000 [00:00<01:29, 22.27 step/s, accuracy=0.88, loss=0.54, step=5e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 50000, best model saved. (accuracy=0.7899)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:32<00:00, 21.62 step/s, accuracy=0.78, loss=0.76, step=52000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 523.96 uttr/s, accuracy=0.79, loss=0.91]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.60 step/s, accuracy=0.88, loss=0.31, step=54000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 521.31 uttr/s, accuracy=0.79, loss=0.89]\n",
            "Train: 100% 2000/2000 [01:34<00:00, 21.20 step/s, accuracy=0.81, loss=0.58, step=56000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 534.38 uttr/s, accuracy=0.79, loss=0.92]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.74 step/s, accuracy=0.91, loss=0.33, step=58000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 515.73 uttr/s, accuracy=0.80, loss=0.87]\n",
            "Train: 100% 2000/2000 [01:35<00:00, 20.89 step/s, accuracy=0.75, loss=0.75, step=6e+4]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 532.49 uttr/s, accuracy=0.79, loss=0.88]\n",
            "Train:   0% 7/2000 [00:00<02:52, 11.55 step/s, accuracy=0.84, loss=0.49, step=6e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 60000, best model saved. (accuracy=0.7991)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:36<00:00, 20.79 step/s, accuracy=0.94, loss=0.23, step=62000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 518.58 uttr/s, accuracy=0.79, loss=0.92]\n",
            "Train: 100% 2000/2000 [01:35<00:00, 20.88 step/s, accuracy=0.81, loss=0.59, step=64000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 537.41 uttr/s, accuracy=0.79, loss=0.90]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.80 step/s, accuracy=0.88, loss=0.55, step=66000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 536.25 uttr/s, accuracy=0.80, loss=0.87]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.69 step/s, accuracy=0.88, loss=0.45, step=68000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 545.04 uttr/s, accuracy=0.80, loss=0.86]\n",
            "Train: 100% 2000/2000 [01:37<00:00, 20.42 step/s, accuracy=1.00, loss=0.15, step=7e+4]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 548.26 uttr/s, accuracy=0.80, loss=0.87]\n",
            "Train:   0% 8/2000 [00:00<01:36, 20.66 step/s, accuracy=0.88, loss=0.67, step=7e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 70000, best model saved. (accuracy=0.8005)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:38<00:00, 20.32 step/s, accuracy=0.91, loss=0.61, step=72000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 546.24 uttr/s, accuracy=0.81, loss=0.82]\n",
            "Train: 100% 2000/2000 [01:37<00:00, 20.41 step/s, accuracy=0.94, loss=0.29, step=74000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 549.35 uttr/s, accuracy=0.81, loss=0.81]\n",
            "Train: 100% 2000/2000 [01:38<00:00, 20.30 step/s, accuracy=0.81, loss=0.78, step=76000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 537.20 uttr/s, accuracy=0.81, loss=0.81]\n",
            "Train: 100% 2000/2000 [01:38<00:00, 20.23 step/s, accuracy=0.81, loss=0.74, step=78000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 543.39 uttr/s, accuracy=0.81, loss=0.82]\n",
            "Train: 100% 2000/2000 [01:39<00:00, 20.14 step/s, accuracy=0.97, loss=0.15, step=8e+4]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 543.01 uttr/s, accuracy=0.80, loss=0.85]\n",
            "Train:   0% 8/2000 [00:00<01:36, 20.62 step/s, accuracy=0.81, loss=0.44, step=8e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 80000, best model saved. (accuracy=0.8122)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:40<00:00, 19.93 step/s, accuracy=0.91, loss=0.23, step=82000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 559.60 uttr/s, accuracy=0.81, loss=0.84]\n",
            "Train: 100% 2000/2000 [01:37<00:00, 20.56 step/s, accuracy=0.94, loss=0.27, step=84000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 544.61 uttr/s, accuracy=0.82, loss=0.81]\n",
            "Train: 100% 2000/2000 [01:38<00:00, 20.29 step/s, accuracy=0.94, loss=0.32, step=86000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 548.33 uttr/s, accuracy=0.81, loss=0.84]\n",
            "Train: 100% 2000/2000 [01:37<00:00, 20.49 step/s, accuracy=0.91, loss=0.27, step=88000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 535.17 uttr/s, accuracy=0.82, loss=0.78]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.74 step/s, accuracy=0.91, loss=0.58, step=9e+4]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 535.36 uttr/s, accuracy=0.82, loss=0.78]\n",
            "Train:   0% 6/2000 [00:00<02:58, 11.16 step/s, accuracy=0.94, loss=0.22, step=9e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 90000, best model saved. (accuracy=0.8249)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:36<00:00, 20.75 step/s, accuracy=0.88, loss=0.57, step=92000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 546.96 uttr/s, accuracy=0.82, loss=0.76]\n",
            "Train: 100% 2000/2000 [01:35<00:00, 21.01 step/s, accuracy=1.00, loss=0.13, step=94000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 543.53 uttr/s, accuracy=0.82, loss=0.77]\n",
            "Train: 100% 2000/2000 [01:37<00:00, 20.62 step/s, accuracy=0.78, loss=0.49, step=96000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 535.10 uttr/s, accuracy=0.82, loss=0.77]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.76 step/s, accuracy=0.91, loss=0.27, step=98000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 522.49 uttr/s, accuracy=0.81, loss=0.83]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.82 step/s, accuracy=0.97, loss=0.11, step=1e+5]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 522.85 uttr/s, accuracy=0.81, loss=0.81]\n",
            "Train:   0% 7/2000 [00:00<01:42, 19.49 step/s, accuracy=0.94, loss=0.25, step=1e+5]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100000, best model saved. (accuracy=0.8249)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:35<00:00, 20.86 step/s, accuracy=0.88, loss=0.28, step=102000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 530.56 uttr/s, accuracy=0.82, loss=0.80]\n",
            "Train: 100% 2000/2000 [01:34<00:00, 21.26 step/s, accuracy=0.94, loss=0.36, step=104000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 532.41 uttr/s, accuracy=0.82, loss=0.77]\n",
            "Train: 100% 2000/2000 [01:33<00:00, 21.29 step/s, accuracy=0.94, loss=0.27, step=106000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 529.67 uttr/s, accuracy=0.82, loss=0.79]\n",
            "Train: 100% 2000/2000 [01:34<00:00, 21.09 step/s, accuracy=0.88, loss=0.38, step=108000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 540.58 uttr/s, accuracy=0.83, loss=0.74]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.68 step/s, accuracy=0.88, loss=0.62, step=110000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 551.47 uttr/s, accuracy=0.82, loss=0.79]\n",
            "Train:   0% 8/2000 [00:00<03:00, 11.02 step/s, accuracy=0.97, loss=0.14, step=110008]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 110000, best model saved. (accuracy=0.8317)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:32<00:00, 21.59 step/s, accuracy=0.84, loss=0.47, step=112000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 567.43 uttr/s, accuracy=0.83, loss=0.73]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.63 step/s, accuracy=0.94, loss=0.33, step=114000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 558.45 uttr/s, accuracy=0.83, loss=0.74]\n",
            "Train: 100% 2000/2000 [01:30<00:00, 22.00 step/s, accuracy=0.94, loss=0.27, step=116000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 556.01 uttr/s, accuracy=0.82, loss=0.77]\n",
            "Train: 100% 2000/2000 [01:31<00:00, 21.90 step/s, accuracy=0.94, loss=0.44, step=118000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 557.35 uttr/s, accuracy=0.83, loss=0.75]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.52 step/s, accuracy=0.91, loss=0.26, step=120000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 554.84 uttr/s, accuracy=0.82, loss=0.79]\n",
            "Train:   0% 6/2000 [00:00<02:41, 12.37 step/s, accuracy=0.94, loss=0.33, step=120006]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 120000, best model saved. (accuracy=0.8317)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:33<00:00, 21.39 step/s, accuracy=0.81, loss=0.52, step=122000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 538.92 uttr/s, accuracy=0.84, loss=0.72]\n",
            "Train: 100% 2000/2000 [01:34<00:00, 21.22 step/s, accuracy=0.97, loss=0.18, step=124000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 473.33 uttr/s, accuracy=0.83, loss=0.74]\n",
            "Train: 100% 2000/2000 [01:41<00:00, 19.79 step/s, accuracy=1.00, loss=0.07, step=126000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 488.23 uttr/s, accuracy=0.83, loss=0.75]\n",
            "Train: 100% 2000/2000 [01:33<00:00, 21.30 step/s, accuracy=0.94, loss=0.21, step=128000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 536.97 uttr/s, accuracy=0.82, loss=0.81]\n",
            "Train: 100% 2000/2000 [01:29<00:00, 22.23 step/s, accuracy=0.84, loss=0.35, step=130000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 505.92 uttr/s, accuracy=0.82, loss=0.78]\n",
            "Train:   0% 7/2000 [00:00<02:44, 12.12 step/s, accuracy=0.97, loss=0.14, step=130007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 130000, best model saved. (accuracy=0.8363)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:30<00:00, 22.13 step/s, accuracy=0.97, loss=0.17, step=132000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 516.14 uttr/s, accuracy=0.83, loss=0.75]\n",
            "Train: 100% 2000/2000 [01:30<00:00, 22.19 step/s, accuracy=0.94, loss=0.21, step=134000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 535.32 uttr/s, accuracy=0.82, loss=0.79]\n",
            "Train: 100% 2000/2000 [01:31<00:00, 21.97 step/s, accuracy=1.00, loss=0.06, step=136000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 527.18 uttr/s, accuracy=0.83, loss=0.74]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.58 step/s, accuracy=0.94, loss=0.26, step=138000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 542.00 uttr/s, accuracy=0.84, loss=0.73]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.64 step/s, accuracy=0.91, loss=0.30, step=140000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 532.63 uttr/s, accuracy=0.84, loss=0.72]\n",
            "Train:   0% 7/2000 [00:00<01:42, 19.36 step/s, accuracy=1.00, loss=0.08, step=140007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 140000, best model saved. (accuracy=0.8386)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:36<00:00, 20.69 step/s, accuracy=0.94, loss=0.23, step=142000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 539.04 uttr/s, accuracy=0.83, loss=0.75]\n",
            "Train: 100% 2000/2000 [01:35<00:00, 20.88 step/s, accuracy=0.84, loss=0.35, step=144000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 532.61 uttr/s, accuracy=0.84, loss=0.73]\n",
            "Train: 100% 2000/2000 [01:35<00:00, 20.91 step/s, accuracy=0.78, loss=0.54, step=146000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 521.89 uttr/s, accuracy=0.83, loss=0.73]\n",
            "Train: 100% 2000/2000 [01:35<00:00, 20.91 step/s, accuracy=0.97, loss=0.18, step=148000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 526.53 uttr/s, accuracy=0.84, loss=0.74]\n",
            "Train: 100% 2000/2000 [01:37<00:00, 20.57 step/s, accuracy=0.88, loss=0.38, step=150000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 541.94 uttr/s, accuracy=0.83, loss=0.74]\n",
            "Train:   0% 8/2000 [00:00<01:37, 20.43 step/s, accuracy=0.94, loss=0.33, step=150008]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 150000, best model saved. (accuracy=0.8386)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:37<00:00, 20.46 step/s, accuracy=0.84, loss=0.51, step=152000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 556.22 uttr/s, accuracy=0.83, loss=0.73]\n",
            "Train: 100% 2000/2000 [01:38<00:00, 20.22 step/s, accuracy=0.94, loss=0.17, step=154000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 525.07 uttr/s, accuracy=0.83, loss=0.74]\n",
            "Train: 100% 2000/2000 [01:37<00:00, 20.55 step/s, accuracy=0.84, loss=0.40, step=156000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 545.53 uttr/s, accuracy=0.84, loss=0.70]\n",
            "Train: 100% 2000/2000 [01:39<00:00, 20.20 step/s, accuracy=0.94, loss=0.12, step=158000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 548.98 uttr/s, accuracy=0.85, loss=0.66]\n",
            "Train: 100% 2000/2000 [01:39<00:00, 20.02 step/s, accuracy=0.97, loss=0.17, step=160000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 550.18 uttr/s, accuracy=0.84, loss=0.70]\n",
            "Train:   0% 7/2000 [00:00<02:40, 12.44 step/s, accuracy=0.88, loss=0.46, step=160007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 160000, best model saved. (accuracy=0.8520)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:40<00:00, 19.91 step/s, accuracy=0.94, loss=0.19, step=162000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 547.37 uttr/s, accuracy=0.83, loss=0.75]\n",
            "Train: 100% 2000/2000 [01:39<00:00, 20.03 step/s, accuracy=1.00, loss=0.06, step=164000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 560.98 uttr/s, accuracy=0.86, loss=0.65]\n",
            "Train: 100% 2000/2000 [01:38<00:00, 20.24 step/s, accuracy=1.00, loss=0.06, step=166000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 557.89 uttr/s, accuracy=0.84, loss=0.67]\n",
            "Train: 100% 2000/2000 [01:37<00:00, 20.42 step/s, accuracy=0.91, loss=0.26, step=168000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 560.21 uttr/s, accuracy=0.84, loss=0.69]\n",
            "Train: 100% 2000/2000 [01:38<00:00, 20.39 step/s, accuracy=1.00, loss=0.03, step=170000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 556.81 uttr/s, accuracy=0.85, loss=0.68]\n",
            "Train:   0% 7/2000 [00:00<01:42, 19.49 step/s, accuracy=0.97, loss=0.20, step=170007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 170000, best model saved. (accuracy=0.8556)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:37<00:00, 20.51 step/s, accuracy=1.00, loss=0.05, step=172000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 548.40 uttr/s, accuracy=0.85, loss=0.67]\n",
            "Train: 100% 2000/2000 [01:37<00:00, 20.60 step/s, accuracy=1.00, loss=0.12, step=174000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 544.96 uttr/s, accuracy=0.85, loss=0.67]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.74 step/s, accuracy=1.00, loss=0.11, step=176000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 546.15 uttr/s, accuracy=0.85, loss=0.67]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.75 step/s, accuracy=1.00, loss=0.04, step=178000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 541.90 uttr/s, accuracy=0.84, loss=0.71]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.70 step/s, accuracy=1.00, loss=0.02, step=180000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 524.75 uttr/s, accuracy=0.84, loss=0.67]\n",
            "Train:   0% 6/2000 [00:00<01:40, 19.78 step/s, accuracy=0.94, loss=0.23, step=180006]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 180000, best model saved. (accuracy=0.8556)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:35<00:00, 20.83 step/s, accuracy=0.97, loss=0.15, step=182000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 527.40 uttr/s, accuracy=0.84, loss=0.68]\n",
            "Train: 100% 2000/2000 [01:35<00:00, 21.02 step/s, accuracy=1.00, loss=0.04, step=184000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 537.13 uttr/s, accuracy=0.85, loss=0.68]\n",
            "Train: 100% 2000/2000 [01:34<00:00, 21.09 step/s, accuracy=0.91, loss=0.41, step=186000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 540.22 uttr/s, accuracy=0.85, loss=0.66]\n",
            "Train: 100% 2000/2000 [01:33<00:00, 21.37 step/s, accuracy=0.94, loss=0.26, step=188000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 547.33 uttr/s, accuracy=0.85, loss=0.68]\n",
            "Train: 100% 2000/2000 [01:33<00:00, 21.48 step/s, accuracy=0.97, loss=0.14, step=190000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 549.09 uttr/s, accuracy=0.85, loss=0.67]\n",
            "Train:   0% 7/2000 [00:00<05:09,  6.44 step/s, accuracy=1.00, loss=0.08, step=190007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 190000, best model saved. (accuracy=0.8556)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:33<00:00, 21.28 step/s, accuracy=0.94, loss=0.30, step=192000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 557.94 uttr/s, accuracy=0.85, loss=0.67]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.64 step/s, accuracy=0.94, loss=0.15, step=194000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 556.48 uttr/s, accuracy=0.86, loss=0.64]\n",
            "Train: 100% 2000/2000 [01:33<00:00, 21.49 step/s, accuracy=1.00, loss=0.08, step=196000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 547.20 uttr/s, accuracy=0.84, loss=0.68]\n",
            "Train: 100% 2000/2000 [01:34<00:00, 21.17 step/s, accuracy=1.00, loss=0.12, step=198000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 552.29 uttr/s, accuracy=0.85, loss=0.65]\n",
            "Train: 100% 2000/2000 [01:31<00:00, 21.80 step/s, accuracy=0.91, loss=0.33, step=2e+5]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 553.29 uttr/s, accuracy=0.85, loss=0.66]\n",
            "Train:   0% 7/2000 [00:00<02:37, 12.69 step/s, accuracy=0.91, loss=0.22, step=2e+5]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 200000, best model saved. (accuracy=0.8574)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:33<00:00, 21.41 step/s, accuracy=1.00, loss=0.06, step=202000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 546.12 uttr/s, accuracy=0.85, loss=0.65]\n",
            "Train: 100% 2000/2000 [01:33<00:00, 21.44 step/s, accuracy=0.97, loss=0.14, step=204000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 545.55 uttr/s, accuracy=0.85, loss=0.67]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.62 step/s, accuracy=0.97, loss=0.14, step=206000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 545.62 uttr/s, accuracy=0.85, loss=0.66]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.52 step/s, accuracy=1.00, loss=0.04, step=208000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 545.68 uttr/s, accuracy=0.85, loss=0.65]\n",
            "Train: 100% 2000/2000 [01:33<00:00, 21.44 step/s, accuracy=0.94, loss=0.29, step=210000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 537.67 uttr/s, accuracy=0.85, loss=0.69]\n",
            "Train:   0% 7/2000 [00:00<02:45, 12.02 step/s, accuracy=0.94, loss=0.19, step=210007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 210000, best model saved. (accuracy=0.8574)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:33<00:00, 21.35 step/s, accuracy=0.97, loss=0.16, step=212000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 525.31 uttr/s, accuracy=0.85, loss=0.66]\n",
            "Train: 100% 2000/2000 [01:32<00:00, 21.65 step/s, accuracy=0.94, loss=0.14, step=214000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 521.47 uttr/s, accuracy=0.86, loss=0.62]\n",
            "Train: 100% 2000/2000 [01:34<00:00, 21.26 step/s, accuracy=0.94, loss=0.22, step=216000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 527.62 uttr/s, accuracy=0.85, loss=0.67]\n",
            "Train: 100% 2000/2000 [01:35<00:00, 20.99 step/s, accuracy=0.91, loss=0.48, step=218000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 518.71 uttr/s, accuracy=0.86, loss=0.62]\n",
            "Train: 100% 2000/2000 [01:36<00:00, 20.75 step/s, accuracy=0.91, loss=0.22, step=220000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 518.87 uttr/s, accuracy=0.86, loss=0.67]\n",
            "Train:   0% 8/2000 [00:00<01:40, 19.80 step/s, accuracy=1.00, loss=0.06, step=220008]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 220000, best model saved. (accuracy=0.8602)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:37<00:00, 20.45 step/s, accuracy=0.97, loss=0.09, step=222000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 540.76 uttr/s, accuracy=0.85, loss=0.64]\n",
            "Train: 100% 2000/2000 [01:38<00:00, 20.37 step/s, accuracy=1.00, loss=0.04, step=224000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 532.32 uttr/s, accuracy=0.85, loss=0.65]\n",
            "Train: 100% 2000/2000 [01:38<00:00, 20.36 step/s, accuracy=0.97, loss=0.11, step=226000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 529.17 uttr/s, accuracy=0.86, loss=0.65]\n",
            "Train: 100% 2000/2000 [01:38<00:00, 20.27 step/s, accuracy=1.00, loss=0.09, step=228000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 533.10 uttr/s, accuracy=0.85, loss=0.68]\n",
            "Train: 100% 2000/2000 [01:40<00:00, 19.95 step/s, accuracy=0.97, loss=0.19, step=230000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 534.04 uttr/s, accuracy=0.86, loss=0.61]\n",
            "Train:   0% 7/2000 [00:00<01:39, 20.11 step/s, accuracy=0.97, loss=0.15, step=230007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 230000, best model saved. (accuracy=0.8616)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:40<00:00, 19.96 step/s, accuracy=0.94, loss=0.10, step=232000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 543.55 uttr/s, accuracy=0.86, loss=0.62]\n",
            "Train: 100% 2000/2000 [01:40<00:00, 19.86 step/s, accuracy=0.97, loss=0.22, step=234000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 540.41 uttr/s, accuracy=0.86, loss=0.64]\n",
            "Train: 100% 2000/2000 [01:41<00:00, 19.72 step/s, accuracy=0.97, loss=0.13, step=236000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 534.22 uttr/s, accuracy=0.86, loss=0.62]\n",
            "Train: 100% 2000/2000 [01:41<00:00, 19.64 step/s, accuracy=0.97, loss=0.09, step=238000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 526.29 uttr/s, accuracy=0.86, loss=0.62]\n",
            "Train: 100% 2000/2000 [01:42<00:00, 19.45 step/s, accuracy=1.00, loss=0.03, step=240000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 529.98 uttr/s, accuracy=0.86, loss=0.64]\n",
            "Train:   0% 7/2000 [00:00<01:38, 20.17 step/s, accuracy=0.94, loss=0.30, step=240007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 240000, best model saved. (accuracy=0.8636)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:44<00:00, 19.21 step/s, accuracy=1.00, loss=0.07, step=242000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 540.42 uttr/s, accuracy=0.86, loss=0.62]\n",
            "Train: 100% 2000/2000 [01:43<00:00, 19.30 step/s, accuracy=1.00, loss=0.04, step=244000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 555.10 uttr/s, accuracy=0.86, loss=0.63]\n",
            "Train: 100% 2000/2000 [01:44<00:00, 19.08 step/s, accuracy=1.00, loss=0.05, step=246000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 563.80 uttr/s, accuracy=0.86, loss=0.65]\n",
            "Train: 100% 2000/2000 [01:43<00:00, 19.27 step/s, accuracy=1.00, loss=0.06, step=248000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 559.25 uttr/s, accuracy=0.86, loss=0.61]\n",
            "Train: 100% 2000/2000 [01:43<00:00, 19.34 step/s, accuracy=0.97, loss=0.14, step=250000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 551.03 uttr/s, accuracy=0.87, loss=0.62]\n",
            "Train:   0% 7/2000 [00:00<03:06, 10.68 step/s, accuracy=0.97, loss=0.10, step=250007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 250000, best model saved. (accuracy=0.8666)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:43<00:00, 19.39 step/s, accuracy=1.00, loss=0.05, step=252000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 552.87 uttr/s, accuracy=0.87, loss=0.59]\n",
            "Train: 100% 2000/2000 [01:42<00:00, 19.52 step/s, accuracy=0.94, loss=0.23, step=254000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 550.48 uttr/s, accuracy=0.87, loss=0.58]\n",
            "Train: 100% 2000/2000 [01:42<00:00, 19.46 step/s, accuracy=0.97, loss=0.07, step=256000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 555.26 uttr/s, accuracy=0.87, loss=0.57]\n",
            "Train: 100% 2000/2000 [01:43<00:00, 19.36 step/s, accuracy=1.00, loss=0.03, step=258000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 552.13 uttr/s, accuracy=0.87, loss=0.60]\n",
            "Train: 100% 2000/2000 [01:43<00:00, 19.29 step/s, accuracy=0.97, loss=0.07, step=260000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 554.71 uttr/s, accuracy=0.87, loss=0.61]\n",
            "Train:   0% 7/2000 [00:00<03:13, 10.31 step/s, accuracy=1.00, loss=0.03, step=260007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 260000, best model saved. (accuracy=0.8726)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:44<00:00, 19.22 step/s, accuracy=0.94, loss=0.09, step=262000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 555.35 uttr/s, accuracy=0.87, loss=0.60]\n",
            "Train: 100% 2000/2000 [01:43<00:00, 19.29 step/s, accuracy=1.00, loss=0.06, step=264000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 549.87 uttr/s, accuracy=0.87, loss=0.59]\n",
            "Train: 100% 2000/2000 [01:43<00:00, 19.37 step/s, accuracy=0.91, loss=0.19, step=266000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 546.21 uttr/s, accuracy=0.87, loss=0.58]\n",
            "Train: 100% 2000/2000 [01:41<00:00, 19.64 step/s, accuracy=1.00, loss=0.06, step=268000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 551.27 uttr/s, accuracy=0.86, loss=0.61]\n",
            "Train: 100% 2000/2000 [01:42<00:00, 19.53 step/s, accuracy=0.97, loss=0.08, step=270000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 539.57 uttr/s, accuracy=0.87, loss=0.60]\n",
            "Train:   0% 7/2000 [00:00<03:14, 10.26 step/s, accuracy=1.00, loss=0.01, step=270007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 270000, best model saved. (accuracy=0.8726)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:41<00:00, 19.65 step/s, accuracy=0.97, loss=0.08, step=272000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 541.52 uttr/s, accuracy=0.87, loss=0.57]\n",
            "Train: 100% 2000/2000 [01:41<00:00, 19.68 step/s, accuracy=1.00, loss=0.08, step=274000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 535.65 uttr/s, accuracy=0.88, loss=0.56]\n",
            "Train: 100% 2000/2000 [01:41<00:00, 19.65 step/s, accuracy=1.00, loss=0.06, step=276000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 527.03 uttr/s, accuracy=0.87, loss=0.58]\n",
            "Train: 100% 2000/2000 [01:41<00:00, 19.63 step/s, accuracy=1.00, loss=0.04, step=278000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 523.00 uttr/s, accuracy=0.88, loss=0.56]\n",
            "Train: 100% 2000/2000 [01:41<00:00, 19.80 step/s, accuracy=0.97, loss=0.10, step=280000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 517.23 uttr/s, accuracy=0.87, loss=0.58]\n",
            "Train:   0% 7/2000 [00:00<01:37, 20.49 step/s, accuracy=0.97, loss=0.19, step=280007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 280000, best model saved. (accuracy=0.8786)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:41<00:00, 19.69 step/s, accuracy=1.00, loss=0.05, step=282000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 537.91 uttr/s, accuracy=0.87, loss=0.58]\n",
            "Train: 100% 2000/2000 [01:40<00:00, 19.89 step/s, accuracy=0.94, loss=0.13, step=284000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 542.72 uttr/s, accuracy=0.87, loss=0.58]\n",
            "Train: 100% 2000/2000 [01:39<00:00, 20.08 step/s, accuracy=1.00, loss=0.03, step=286000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 546.34 uttr/s, accuracy=0.87, loss=0.56]\n",
            "Train: 100% 2000/2000 [01:40<00:00, 19.86 step/s, accuracy=1.00, loss=0.02, step=288000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 530.06 uttr/s, accuracy=0.88, loss=0.57]\n",
            "Train: 100% 2000/2000 [01:39<00:00, 20.05 step/s, accuracy=1.00, loss=0.03, step=290000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 529.91 uttr/s, accuracy=0.88, loss=0.57]\n",
            "Train:   0% 7/2000 [00:00<03:13, 10.32 step/s, accuracy=1.00, loss=0.06, step=290007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 290000, best model saved. (accuracy=0.8789)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:40<00:00, 19.93 step/s, accuracy=0.97, loss=0.09, step=292000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 534.01 uttr/s, accuracy=0.88, loss=0.56]\n",
            "Train: 100% 2000/2000 [01:41<00:00, 19.66 step/s, accuracy=0.97, loss=0.05, step=294000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 535.74 uttr/s, accuracy=0.88, loss=0.52]\n",
            "Train: 100% 2000/2000 [01:41<00:00, 19.69 step/s, accuracy=1.00, loss=0.03, step=296000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 521.86 uttr/s, accuracy=0.88, loss=0.54]\n",
            "Train: 100% 2000/2000 [01:42<00:00, 19.60 step/s, accuracy=1.00, loss=0.03, step=298000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 523.95 uttr/s, accuracy=0.88, loss=0.55]\n",
            "Train: 100% 2000/2000 [01:43<00:00, 19.36 step/s, accuracy=0.97, loss=0.04, step=3e+5]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 530.95 uttr/s, accuracy=0.88, loss=0.55]\n",
            "Train:   0% 7/2000 [00:00<02:38, 12.57 step/s, accuracy=0.94, loss=0.18, step=3e+5]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 300000, best model saved. (accuracy=0.8842)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:43<00:00, 19.28 step/s, accuracy=0.97, loss=0.03, step=302000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 524.18 uttr/s, accuracy=0.88, loss=0.52]\n",
            "Train: 100% 2000/2000 [01:44<00:00, 19.15 step/s, accuracy=0.97, loss=0.08, step=304000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 528.29 uttr/s, accuracy=0.88, loss=0.54]\n",
            "Train: 100% 2000/2000 [01:46<00:00, 18.83 step/s, accuracy=0.97, loss=0.06, step=306000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 489.02 uttr/s, accuracy=0.88, loss=0.56]\n",
            "Train: 100% 2000/2000 [01:45<00:00, 18.88 step/s, accuracy=1.00, loss=0.02, step=308000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 487.32 uttr/s, accuracy=0.88, loss=0.55]\n",
            "Train: 100% 2000/2000 [01:46<00:00, 18.70 step/s, accuracy=1.00, loss=0.05, step=310000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 495.90 uttr/s, accuracy=0.88, loss=0.54]\n",
            "Train:   0% 8/2000 [00:00<01:38, 20.22 step/s, accuracy=1.00, loss=0.02, step=310008]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 310000, best model saved. (accuracy=0.8849)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:46<00:00, 18.74 step/s, accuracy=1.00, loss=0.02, step=312000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 493.99 uttr/s, accuracy=0.88, loss=0.53]\n",
            "Train: 100% 2000/2000 [01:47<00:00, 18.64 step/s, accuracy=0.97, loss=0.08, step=314000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 503.77 uttr/s, accuracy=0.89, loss=0.52]\n",
            "Train: 100% 2000/2000 [01:48<00:00, 18.37 step/s, accuracy=1.00, loss=0.02, step=316000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 498.99 uttr/s, accuracy=0.88, loss=0.57]\n",
            "Train: 100% 2000/2000 [01:49<00:00, 18.22 step/s, accuracy=0.97, loss=0.07, step=318000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 506.49 uttr/s, accuracy=0.89, loss=0.52]\n",
            "Train: 100% 2000/2000 [01:50<00:00, 18.13 step/s, accuracy=1.00, loss=0.06, step=320000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 510.93 uttr/s, accuracy=0.88, loss=0.54]\n",
            "Train:   0% 7/2000 [00:00<01:39, 20.10 step/s, accuracy=1.00, loss=0.03, step=320007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 320000, best model saved. (accuracy=0.8878)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:50<00:00, 18.04 step/s, accuracy=0.97, loss=0.05, step=322000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 510.32 uttr/s, accuracy=0.89, loss=0.53]\n",
            "Train: 100% 2000/2000 [01:51<00:00, 17.94 step/s, accuracy=1.00, loss=0.07, step=324000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 515.17 uttr/s, accuracy=0.88, loss=0.54]\n",
            "Train: 100% 2000/2000 [01:51<00:00, 17.86 step/s, accuracy=1.00, loss=0.01, step=326000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 545.30 uttr/s, accuracy=0.89, loss=0.50]\n",
            "Train: 100% 2000/2000 [01:51<00:00, 17.97 step/s, accuracy=1.00, loss=0.01, step=328000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 532.34 uttr/s, accuracy=0.89, loss=0.52]\n",
            "Train: 100% 2000/2000 [01:50<00:00, 18.10 step/s, accuracy=0.97, loss=0.09, step=330000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 534.54 uttr/s, accuracy=0.89, loss=0.53]\n",
            "Train:   0% 7/2000 [00:00<03:12, 10.38 step/s, accuracy=1.00, loss=0.04, step=330007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 330000, best model saved. (accuracy=0.8936)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:50<00:00, 18.06 step/s, accuracy=0.97, loss=0.22, step=332000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 542.12 uttr/s, accuracy=0.88, loss=0.51]\n",
            "Train: 100% 2000/2000 [01:50<00:00, 18.10 step/s, accuracy=1.00, loss=0.01, step=334000]\n",
            "Valid: 100% 6944/6944 [00:12<00:00, 539.05 uttr/s, accuracy=0.89, loss=0.51]\n",
            "Train: 100% 2000/2000 [01:49<00:00, 18.29 step/s, accuracy=1.00, loss=0.01, step=336000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 522.06 uttr/s, accuracy=0.89, loss=0.52]\n",
            "Train: 100% 2000/2000 [01:50<00:00, 18.08 step/s, accuracy=1.00, loss=0.01, step=338000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 526.25 uttr/s, accuracy=0.88, loss=0.51]\n",
            "Train: 100% 2000/2000 [01:50<00:00, 18.18 step/s, accuracy=1.00, loss=0.01, step=340000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 514.17 uttr/s, accuracy=0.89, loss=0.50]\n",
            "Train:   0% 7/2000 [00:00<02:57, 11.22 step/s, accuracy=0.97, loss=0.04, step=340007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 340000, best model saved. (accuracy=0.8936)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:50<00:00, 18.17 step/s, accuracy=1.00, loss=0.01, step=342000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 515.20 uttr/s, accuracy=0.89, loss=0.51]\n",
            "Train: 100% 2000/2000 [01:50<00:00, 18.04 step/s, accuracy=0.94, loss=0.10, step=344000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 503.99 uttr/s, accuracy=0.89, loss=0.52]\n",
            "Train: 100% 2000/2000 [01:51<00:00, 17.97 step/s, accuracy=1.00, loss=0.01, step=346000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 505.28 uttr/s, accuracy=0.89, loss=0.50]\n",
            "Train: 100% 2000/2000 [01:50<00:00, 18.17 step/s, accuracy=0.97, loss=0.03, step=348000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 503.48 uttr/s, accuracy=0.89, loss=0.53]\n",
            "Train: 100% 2000/2000 [01:49<00:00, 18.26 step/s, accuracy=1.00, loss=0.04, step=350000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 501.97 uttr/s, accuracy=0.89, loss=0.50]\n",
            "Train:   0% 7/2000 [00:00<03:12, 10.38 step/s, accuracy=1.00, loss=0.02, step=350007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 350000, best model saved. (accuracy=0.8936)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:50<00:00, 18.17 step/s, accuracy=1.00, loss=0.03, step=352000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 501.97 uttr/s, accuracy=0.89, loss=0.49]\n",
            "Train: 100% 2000/2000 [01:48<00:00, 18.36 step/s, accuracy=1.00, loss=0.01, step=354000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 507.52 uttr/s, accuracy=0.90, loss=0.50]\n",
            "Train: 100% 2000/2000 [01:48<00:00, 18.49 step/s, accuracy=1.00, loss=0.01, step=356000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 497.96 uttr/s, accuracy=0.89, loss=0.49]\n",
            "Train: 100% 2000/2000 [01:48<00:00, 18.44 step/s, accuracy=1.00, loss=0.02, step=358000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 488.65 uttr/s, accuracy=0.89, loss=0.50]\n",
            "Train: 100% 2000/2000 [01:48<00:00, 18.41 step/s, accuracy=1.00, loss=0.02, step=360000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 490.96 uttr/s, accuracy=0.89, loss=0.50]\n",
            "Train:   0% 8/2000 [00:00<03:01, 11.00 step/s, accuracy=1.00, loss=0.01, step=360008]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 360000, best model saved. (accuracy=0.8954)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:48<00:00, 18.49 step/s, accuracy=1.00, loss=0.01, step=362000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 481.78 uttr/s, accuracy=0.89, loss=0.51]\n",
            "Train: 100% 2000/2000 [01:47<00:00, 18.60 step/s, accuracy=1.00, loss=0.01, step=364000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 484.55 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:47<00:00, 18.67 step/s, accuracy=1.00, loss=0.01, step=366000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 489.65 uttr/s, accuracy=0.90, loss=0.50]\n",
            "Train: 100% 2000/2000 [01:47<00:00, 18.57 step/s, accuracy=1.00, loss=0.02, step=368000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 478.34 uttr/s, accuracy=0.89, loss=0.50]\n",
            "Train: 100% 2000/2000 [01:46<00:00, 18.75 step/s, accuracy=1.00, loss=0.04, step=370000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 471.68 uttr/s, accuracy=0.89, loss=0.49]\n",
            "Train:   0% 8/2000 [00:00<02:34, 12.88 step/s, accuracy=1.00, loss=0.01, step=370008]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 370000, best model saved. (accuracy=0.8965)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:45<00:00, 18.90 step/s, accuracy=1.00, loss=0.03, step=372000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 464.51 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:45<00:00, 18.90 step/s, accuracy=1.00, loss=0.01, step=374000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 471.59 uttr/s, accuracy=0.89, loss=0.49]\n",
            "Train: 100% 2000/2000 [01:46<00:00, 18.73 step/s, accuracy=1.00, loss=0.01, step=376000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 459.21 uttr/s, accuracy=0.90, loss=0.49]\n",
            "Train: 100% 2000/2000 [01:47<00:00, 18.59 step/s, accuracy=1.00, loss=0.01, step=378000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 476.30 uttr/s, accuracy=0.90, loss=0.49]\n",
            "Train: 100% 2000/2000 [01:48<00:00, 18.35 step/s, accuracy=1.00, loss=0.01, step=380000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 460.51 uttr/s, accuracy=0.90, loss=0.47]\n",
            "Train:   0% 8/2000 [00:00<01:36, 20.65 step/s, accuracy=1.00, loss=0.01, step=380008]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 380000, best model saved. (accuracy=0.9005)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:50<00:00, 18.06 step/s, accuracy=1.00, loss=0.02, step=382000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 464.17 uttr/s, accuracy=0.90, loss=0.45]\n",
            "Train: 100% 2000/2000 [01:50<00:00, 18.05 step/s, accuracy=1.00, loss=0.01, step=384000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 455.57 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:51<00:00, 17.96 step/s, accuracy=1.00, loss=0.01, step=386000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 462.30 uttr/s, accuracy=0.89, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:52<00:00, 17.84 step/s, accuracy=1.00, loss=0.01, step=388000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 473.47 uttr/s, accuracy=0.90, loss=0.49]\n",
            "Train: 100% 2000/2000 [01:53<00:00, 17.68 step/s, accuracy=1.00, loss=0.02, step=390000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 475.54 uttr/s, accuracy=0.90, loss=0.47]\n",
            "Train:   0% 8/2000 [00:00<01:37, 20.42 step/s, accuracy=1.00, loss=0.01, step=390008]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 390000, best model saved. (accuracy=0.9024)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:52<00:00, 17.73 step/s, accuracy=1.00, loss=0.02, step=392000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 478.91 uttr/s, accuracy=0.89, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:54<00:00, 17.44 step/s, accuracy=1.00, loss=0.05, step=394000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 471.04 uttr/s, accuracy=0.89, loss=0.49]\n",
            "Train: 100% 2000/2000 [01:54<00:00, 17.47 step/s, accuracy=1.00, loss=0.01, step=396000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 476.27 uttr/s, accuracy=0.90, loss=0.47]\n",
            "Train: 100% 2000/2000 [01:54<00:00, 17.41 step/s, accuracy=1.00, loss=0.04, step=398000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 488.64 uttr/s, accuracy=0.89, loss=0.47]\n",
            "Train: 100% 2000/2000 [01:55<00:00, 17.24 step/s, accuracy=1.00, loss=0.00, step=4e+5]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 482.94 uttr/s, accuracy=0.90, loss=0.47]\n",
            "Train:   0% 7/2000 [00:00<01:39, 20.11 step/s, accuracy=1.00, loss=0.01, step=4e+5]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 400000, best model saved. (accuracy=0.9024)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:56<00:00, 17.22 step/s, accuracy=1.00, loss=0.02, step=402000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 486.28 uttr/s, accuracy=0.90, loss=0.46]\n",
            "Train: 100% 2000/2000 [01:55<00:00, 17.27 step/s, accuracy=1.00, loss=0.04, step=404000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 482.83 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:56<00:00, 17.20 step/s, accuracy=1.00, loss=0.01, step=406000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 499.74 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:57<00:00, 17.00 step/s, accuracy=1.00, loss=0.03, step=408000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 530.76 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:56<00:00, 17.19 step/s, accuracy=1.00, loss=0.01, step=410000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 523.18 uttr/s, accuracy=0.90, loss=0.46]\n",
            "Train:   0% 7/2000 [00:00<02:41, 12.37 step/s, accuracy=1.00, loss=0.00, step=410007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 410000, best model saved. (accuracy=0.9024)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:55<00:00, 17.26 step/s, accuracy=1.00, loss=0.01, step=412000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 521.09 uttr/s, accuracy=0.90, loss=0.45]\n",
            "Train: 100% 2000/2000 [01:54<00:00, 17.41 step/s, accuracy=1.00, loss=0.01, step=414000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 518.59 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:54<00:00, 17.40 step/s, accuracy=1.00, loss=0.00, step=416000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 496.80 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:55<00:00, 17.38 step/s, accuracy=1.00, loss=0.01, step=418000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 494.76 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:54<00:00, 17.39 step/s, accuracy=1.00, loss=0.01, step=420000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 494.78 uttr/s, accuracy=0.90, loss=0.47]\n",
            "Train:   0% 7/2000 [00:00<04:59,  6.65 step/s, accuracy=1.00, loss=0.01, step=420007]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 420000, best model saved. (accuracy=0.9045)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:55<00:00, 17.27 step/s, accuracy=1.00, loss=0.01, step=422000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 485.87 uttr/s, accuracy=0.90, loss=0.46]\n",
            "Train: 100% 2000/2000 [01:56<00:00, 17.12 step/s, accuracy=0.97, loss=0.04, step=424000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 477.08 uttr/s, accuracy=0.90, loss=0.50]\n",
            "Train: 100% 2000/2000 [01:57<00:00, 17.05 step/s, accuracy=1.00, loss=0.01, step=426000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 469.95 uttr/s, accuracy=0.90, loss=0.47]\n",
            "Train: 100% 2000/2000 [01:56<00:00, 17.23 step/s, accuracy=1.00, loss=0.01, step=428000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 479.08 uttr/s, accuracy=0.90, loss=0.46]\n",
            "Train: 100% 2000/2000 [01:55<00:00, 17.35 step/s, accuracy=1.00, loss=0.01, step=430000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 482.14 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train:   0% 8/2000 [00:00<02:59, 11.07 step/s, accuracy=1.00, loss=0.01, step=430008]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 430000, best model saved. (accuracy=0.9050)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:54<00:00, 17.47 step/s, accuracy=1.00, loss=0.00, step=432000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 483.88 uttr/s, accuracy=0.90, loss=0.45]\n",
            "Train: 100% 2000/2000 [01:54<00:00, 17.52 step/s, accuracy=1.00, loss=0.01, step=434000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 475.43 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:53<00:00, 17.59 step/s, accuracy=1.00, loss=0.01, step=436000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 468.57 uttr/s, accuracy=0.90, loss=0.46]\n",
            "Train: 100% 2000/2000 [01:53<00:00, 17.56 step/s, accuracy=1.00, loss=0.01, step=438000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 478.23 uttr/s, accuracy=0.90, loss=0.46]\n",
            "Train: 100% 2000/2000 [01:53<00:00, 17.57 step/s, accuracy=1.00, loss=0.01, step=440000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 460.47 uttr/s, accuracy=0.90, loss=0.47]\n",
            "Train:   0% 8/2000 [00:00<03:12, 10.36 step/s, accuracy=1.00, loss=0.01, step=440008]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 440000, best model saved. (accuracy=0.9050)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [01:53<00:00, 17.69 step/s, accuracy=1.00, loss=0.01, step=442000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 459.96 uttr/s, accuracy=0.90, loss=0.48]\n",
            "Train: 100% 2000/2000 [01:52<00:00, 17.72 step/s, accuracy=1.00, loss=0.01, step=444000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 455.25 uttr/s, accuracy=0.90, loss=0.47]\n",
            "Train: 100% 2000/2000 [01:52<00:00, 17.83 step/s, accuracy=1.00, loss=0.00, step=446000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 454.06 uttr/s, accuracy=0.90, loss=0.46]\n",
            "Train: 100% 2000/2000 [01:52<00:00, 17.73 step/s, accuracy=1.00, loss=0.01, step=448000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 460.64 uttr/s, accuracy=0.90, loss=0.46]\n",
            "Train: 100% 2000/2000 [01:51<00:00, 17.92 step/s, accuracy=1.00, loss=0.01, step=450000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 443.54 uttr/s, accuracy=0.90, loss=0.45]\n",
            "Train:   0% 0/2000 [00:00<?, ? step/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 450000, best model saved. (accuracy=0.9050)\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "  \"\"\"arguments\"\"\"\n",
        "  config = {\n",
        "    \"data_dir\": \"./Dataset\",\n",
        "    \"save_path\": \"model.ckpt\",\n",
        "    \"batch_size\": 32,\n",
        "    \"n_workers\": 8,\n",
        "    \"valid_steps\": 2000,\n",
        "    \"warmup_steps\": 1000,\n",
        "    \"save_steps\": 10000,\n",
        "    \"total_steps\": 450000,\n",
        "  }\n",
        "\n",
        "  return config\n",
        "\n",
        "\n",
        "def main(\n",
        "  data_dir,\n",
        "  save_path,\n",
        "  batch_size,\n",
        "  n_workers,\n",
        "  valid_steps,\n",
        "  warmup_steps,\n",
        "  total_steps,\n",
        "  save_steps,\n",
        "):\n",
        "  \"\"\"Main function.\"\"\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "  train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
        "  train_iterator = iter(train_loader)\n",
        "  print(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "  model = Classifier(n_spks=speaker_num).to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = AdamW(model.parameters(), lr=1e-3)\n",
        "  scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "  print(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "  best_accuracy = -1.0\n",
        "  best_state_dict = None\n",
        "\n",
        "  pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "  for step in range(total_steps):\n",
        "    # Get data\n",
        "    try:\n",
        "      batch = next(train_iterator)\n",
        "    except StopIteration:\n",
        "      train_iterator = iter(train_loader)\n",
        "      batch = next(train_iterator)\n",
        "\n",
        "    loss, accuracy = model_fn(batch, model, criterion, device)\n",
        "    batch_loss = loss.item()\n",
        "    batch_accuracy = accuracy.item()\n",
        "\n",
        "    # Updata model\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Log\n",
        "    pbar.update()\n",
        "    pbar.set_postfix(\n",
        "      loss=f\"{batch_loss:.2f}\",\n",
        "      accuracy=f\"{batch_accuracy:.2f}\",\n",
        "      step=step + 1,\n",
        "    )\n",
        "\n",
        "    # Do validation\n",
        "    if (step + 1) % valid_steps == 0:\n",
        "      pbar.close()\n",
        "\n",
        "      valid_accuracy = valid(valid_loader, model, criterion, device)\n",
        "\n",
        "      # keep the best model\n",
        "      if valid_accuracy > best_accuracy:\n",
        "        best_accuracy = valid_accuracy\n",
        "        best_state_dict = model.state_dict()\n",
        "\n",
        "      pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "    # Save the best model so far.\n",
        "    if (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
        "      torch.save(best_state_dict, save_path)\n",
        "      pbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
        "\n",
        "  pbar.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(**parse_args())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R2rx3AyHpQ-"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_WJpTJNf-gI"
      },
      "source": [
        "# 新增區段"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSuI3WY9Fz78"
      },
      "source": [
        "## Dataset of inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4evns0055Dsx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InferenceDataset(Dataset):\n",
        "  def __init__(self, data_dir):\n",
        "    testdata_path = Path(data_dir) / \"testdata.json\"\n",
        "    metadata = json.load(testdata_path.open())\n",
        "    self.data_dir = data_dir\n",
        "    self.data = metadata[\"utterances\"]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    utterance = self.data[index]\n",
        "    feat_path = utterance[\"feature_path\"]\n",
        "    mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
        "\n",
        "    return feat_path, mel\n",
        "\n",
        "\n",
        "def inference_collate_batch(batch):\n",
        "  \"\"\"Collate a batch of data.\"\"\"\n",
        "  feat_paths, mels = zip(*batch)\n",
        "\n",
        "  return feat_paths, torch.stack(mels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAinHBG1GIWv"
      },
      "source": [
        "## Main funcrion of Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "5e6f383d111d4db394a307b25aa3609e",
            "0628876599ad421cbdb5a475ae030430",
            "b2e23a814c7f42c59e17fd5fbc3ae843",
            "a10fa06ddc7e493da04af65ecbcf3a24",
            "59beedad15444e66976701cea315af15",
            "4ff3d15271cd46959a7f84bf3a3e6a09",
            "7ef3fc9f19f84e36bb9c1488274e103f",
            "c8d37fd89fa04b8f999044a4e0e9aeda"
          ]
        },
        "id": "yQaTt7VDHoRI",
        "outputId": "1f2bb21b-9aeb-4681-fe76-e311a981fae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Use cuda now!\n",
            "[Info]: Finish loading data!\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e6f383d111d4db394a307b25aa3609e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def parse_args():\n",
        "  \"\"\"arguments\"\"\"\n",
        "  config = {\n",
        "    \"data_dir\": \"./Dataset\",\n",
        "    \"model_path\": \"./model.ckpt\",\n",
        "    \"output_path\": \"./output.csv\",\n",
        "  }\n",
        "\n",
        "  return config\n",
        "\n",
        "\n",
        "def main(\n",
        "  data_dir,\n",
        "  model_path,\n",
        "  output_path,\n",
        "):\n",
        "  \"\"\"Main function.\"\"\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "  mapping_path = Path(data_dir) / \"mapping.json\"\n",
        "  mapping = json.load(mapping_path.open())\n",
        "\n",
        "  dataset = InferenceDataset(data_dir)\n",
        "  dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=8,\n",
        "    collate_fn=inference_collate_batch,\n",
        "  )\n",
        "  print(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "  speaker_num = len(mapping[\"id2speaker\"])\n",
        "  model = Classifier(n_spks=speaker_num).to(device)\n",
        "  model.load_state_dict(torch.load(model_path))\n",
        "  model.eval()\n",
        "  print(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "  results = [[\"Id\", \"Category\"]]\n",
        "  for feat_paths, mels in tqdm(dataloader):\n",
        "    with torch.no_grad():\n",
        "      mels = mels.to(device)\n",
        "      outs = model(mels)\n",
        "      preds = outs.argmax(1).cpu().numpy()\n",
        "      for feat_path, pred in zip(feat_paths, preds):\n",
        "        results.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n",
        "  \n",
        "  with open(output_path, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(results)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(**parse_args())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcsGT-QW5CR1"
      },
      "source": [
        "**Reference**\n",
        "https://github.com/lucidrains/conformer\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "0_95833.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0628876599ad421cbdb5a475ae030430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ff3d15271cd46959a7f84bf3a3e6a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59beedad15444e66976701cea315af15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "5e6f383d111d4db394a307b25aa3609e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2e23a814c7f42c59e17fd5fbc3ae843",
              "IPY_MODEL_a10fa06ddc7e493da04af65ecbcf3a24"
            ],
            "layout": "IPY_MODEL_0628876599ad421cbdb5a475ae030430"
          }
        },
        "7ef3fc9f19f84e36bb9c1488274e103f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a10fa06ddc7e493da04af65ecbcf3a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8d37fd89fa04b8f999044a4e0e9aeda",
            "placeholder": "​",
            "style": "IPY_MODEL_7ef3fc9f19f84e36bb9c1488274e103f",
            "value": " 6000/6000 [00:31&lt;00:00, 188.12it/s]"
          }
        },
        "b2e23a814c7f42c59e17fd5fbc3ae843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ff3d15271cd46959a7f84bf3a3e6a09",
            "max": 6000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59beedad15444e66976701cea315af15",
            "value": 6000
          }
        },
        "c8d37fd89fa04b8f999044a4e0e9aeda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
